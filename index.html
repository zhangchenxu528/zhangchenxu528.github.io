<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1//EN" "http://www.w3.org/TR/xhtml11/DTD/xhtml11.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" class="gr__xh-liu_github_io"><head>
<meta name="keywords" content="Chenxu Zhang, CS, UTD, 张晨旭">
<meta name="description" content="Personal page of Chenxu Zhang">
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<link rel="stylesheet" href="jemdoc.css" type="text/css">
<title>Chenxu Zhang</title>
</head>
<body data-gr-c-s-loaded="true">
<table summary="Table for page layout." id="tlayout">
<tbody><tr valign="top">
<td id="layout-menu">
<div class="menu-category">menu</div>
<div class="menu-item"><a href="https://zhangchenxu528.github.io/index.html" class="current">Home</a></div>
<div class="menu-item"><a href="https://zhangchenxu528.github.io/Chenxu_zhang_cv.pdf">Resume</a></div>
</td>
<td id="layout-content">
<div style="margin-top:25px">
<div id="toptitle">
<h1>Chenxu Zhang</h1>
</div>

<table class="imgtable"><tbody><tr>
<td align="left"><p>Research Scientist<br>
<a href="">Intelligent Creation Lab</a> <br>
<a href="">ByteDance</a><br>
682-246-1040 <br>
chenxuzhang@bytedance.com <br> <br>
<a href="https://zhangchenxu528.github.io/Chenxu_zhang_cv.pdf">[CV]</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://scholar.google.com/citations?user=XnefngEAAAAJ&hl=en">[Google Scholar]</a>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<a href="https://github.com/zhangchenxu528">[Github]</a></p>
</td>
<td>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;
&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;<img src="figs/chenxu.jpg" alt="Chenxu Zhang" width="180px" height="200px"></td>
</tr></tbody></table>

	
<h2>Biography</h2>
<p>I am a Research Scientist at the Intelligent Creation Lab, ByteDance. I completed my Ph.D. in Computer Science from the University of Texas at Dallas in 2023, under the supervision of <a href="https://personal.utdallas.edu/~xguo/">Prof. Xiaohu Guo</a>. Prior to that, I earned my Bachelor's degree in Software Engineering in 2015 and Master's degree in Computer Science in 2018, both from Beihang University in Beijing. </p>
<p>My research interests include Computer Graphics, Computer Vision, and AI, with a focus on Talking Face Generation, Conversational Gestures Synthesis, Deblur-NeRF with Human Motion, Text/Image to 3D, and Emotional Talking Avatar. </p>
<p>Feel free to drop me an email if we share common research interests. </p>


<!--
<li>
<p><b>Bytedance, CA</b></p>
<i>Research Scientist (May 2023 &ndash; Present)</i>
<p>Worked on audio-driven personalized emotional talking avatar generation.</p>
</li>

<li>
<p><b>Bytedance, CA</b></p>
<i>Research Intern (May 2021 &ndash; Aug. 2021)</i>
<p>Worked on conversational gestures synthesis from single short video.</p>
</li>
-->
<h2>Working Experience</h2>
<ul>
<li>
<p><b>Bytedance, CA</b></p>
<i>Research Scientist (May 2023 &ndash; Present)</i>
</li>
<li>
<p><b>The University of Texas at Dallas</b></p>
<i>Research Assistant (Jan. 2020 &ndash; May 2023)</i>
</li>
	
<li>
<p><b>Bytedance, CA</b></p>
<i>Research Intern (May 2022 &ndash; Aug. 2022)</i>
</li>

<!-- <li>
<p><b>The University of Texas at Dallas</b></p>
<i>Teaching Assistant (Jan. 2019 &ndash; Jan. 2020)</i>
<p>Worked as a TA in the teaching of: Computer Graphics, Computer Animation.</p>
</li> -->



</ul>


<h2>Research</h2>
<ul>
<br>

<table class="imgtable"><tbody><tr><td>
	<img src="figs/xdyna.gif"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://arxiv.org/abs/2501.10021">X-Dyna: Expressive Dynamic Human Image Animation.</a></b><br>
		Di Chang, Hongyi Xu, You Xie, Yipeng Gao, Zhengfei Kuang, Shengqu Cai, <b>Chenxu Zhang</b>, Guoxian Song, Chao Wang, Yichun Shi, Zeyuan Chen, Shijie Zhou, Linjie Luo, Gordon Wetzstein, Mohammad Soleymani.<br>
		<i>CVPR 2025.</i><span style="color: red;">[Highlight]</span>
		<br>
			<a href="https://arxiv.org/abs/2501.10021">[paper]</a>&nbsp;&nbsp;
	    		<a href="https://x-dyna.github.io/xdyna.github.io/">[project page]</a>&nbsp;&nbsp;
	    		<a href="https://github.com/bytedance/X-Dyna">[code]</a>
	    		<iframe src="https://ghbtns.com/github-btn.html?user=bytedance&repo=X-Dyna&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
	</td></tr></tbody></table><br>

<table class="imgtable"><tbody><tr><td>
	<img src="figs/CADDreamer.gif"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://arxiv.org/pdf/2502.20732">CADDreamer: CAD Object Generation from Single-view Images.</a></b><br>
		Yuan Li, Cheng Lin, Yuan Liu, Xiaoxiao Long, <b>Chenxu Zhang</b>, Ningna Wang, Xin Li, Wenping Wang, Xiaohu Guo.<br>
		<i>CVPR 2025.</i><span style="color: red;">[Highlight]</span>
		<br>
			<a href="https://arxiv.org/pdf/2502.20732">[paper]</a>&nbsp;&nbsp;
	   		<a href="https://lidan233.github.io/caddreamer/">[project page]</a>&nbsp;&nbsp;
	</td></tr></tbody></table><br>
	    
 <table class="imgtable"><tbody><tr><td>
	<img src="figs/xnemo1.gif"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://openreview.net/pdf?id=ML8FH4s5Ts">X-NeMo: Expressive Neural Motion Reenactment via Disentangled Latent Attention.</a></b><br>
		Xiaochen Zhao, Hongyi Xu, Guoxian Song, You Xie, <b>Chenxu Zhang</b>, Xiu Li, Linjie Luo, Jinli Suo, Yebin Liu.<br>
		<i>ICLR 2025.</i>
		<br>
			<a href="https://openreview.net/pdf?id=ML8FH4s5Ts">[paper]</a>&nbsp;&nbsp;
	    		<a href="https://byteaigc.github.io/X-Portrait2/">[project page]</a>&nbsp;&nbsp;
	</td></tr></tbody></table><br>

  <table class="imgtable"><tbody><tr><td>
	<img src="figs/dreamtalk.gif"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
		
        <a  href="https://arxiv.org/abs/2312.13578">MagicTalk: Implicit and Explicit Correlation Learning for Diffusion-based Emotional Talking Face Generation.</a></b><be><br>
	     <b>Chenxu Zhang</b>, Chao Wang, Jianfeng Zhang, Hongyi Xu, Guoxian Song, You Xie, Linjie Luo, Yapeng Tian, Jiashi Feng, Xiaohu Guo.<br>
	    <i>CVMJ 2025.</i>
	    <br>
			<a href="https://arxiv.org/abs/2312.13578">[paper]</a>&nbsp;&nbsp;
	    		<a href="https://magictalk.github.io/">[project page]</a>&nbsp;&nbsp;
	</td></tr></tbody></table><br>

    <table class="imgtable"><tbody><tr><td>
	<img src="figs/avatarstudio.png"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://link.springer.com/article/10.1007/s11263-025-02423-5">AvatarStudio: High-fidelity and Animatable 3D Avatar Creation from Text.</a></b><br>
		Xuanmeng Zhang, Jianfeng Zhang,  <b>Chenxu Zhang</b>, Jun Hao Liew, Huichao Zhang, Yi Yang, Jiashi Feng.<br>
		<i>IJCV 2025.</i>
		<br>
			<a href="https://link.springer.com/article/10.1007/s11263-025-02423-5">[paper]</a>&nbsp;&nbsp;
			<a href="https://avatarstudio23.github.io/">[project page]</a>&nbsp;&nbsp;
			<a href="https://github.com/magic-research/avatarstudio">[code]</a>
	    		<iframe src="https://ghbtns.com/github-btn.html?user=magic-research&repo=avatarstudio&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
	</td></tr></tbody></table><br>

    <table class="imgtable"><tbody><tr><td>
	<img src="figs/diffgesture.png"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://personal.utdallas.edu/~xguo/WACV2025.pdf">Joint Co-Speech Gesture and Expressive Talking Face Generation using Diffusion with Adapters.</a></b><br>
		Steven Hogue, <b>Chenxu Zhang</b>, Yapeng Tian, Xiaohu Guo.<br>
		<i>IJCV 2025.</i>
		<br>
			<a href="https://personal.utdallas.edu/~xguo/WACV2025.pdf">[paper]</a>&nbsp;&nbsp;
			<a href="https://ditzley.github.io/joint-gestures-and-face/">[project page]</a>&nbsp;&nbsp;
			<a href="https://github.com/Ditzley/joint-gestures-and-face">[code]</a>
	    		<iframe src="https://ghbtns.com/github-btn.html?user=Ditzley&repo=joint-gestures-and-face&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
	</td></tr></tbody></table><br>

 <table class="imgtable"><tbody><tr><td>
	<img src="figs/sora.png"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://arxiv.org/abs/2402.17403">Sora Generates Videos with Stunning Geometrical Consistency.</a></b><br>
		Xuanyi Li, Daquan Zhou, <b>Chenxu Zhang</b>, Shaodong Wei, Qibin Hou, Ming-Ming Cheng.<br>
		<i>Preprint'2024.</i>
		<br>
			<a href="https://arxiv.org/abs/2402.17403">[paper]</a>&nbsp;&nbsp;
	    		<a href="https://sora-geometrical-consistency.github.io/">[project page]</a>&nbsp;&nbsp;
			<a href="https://github.com/meteorshowers/Sora-Generates-Videos-with-Stunning-Geometrical-Consistency">[code]</a>
	    		<iframe src="https://ghbtns.com/github-btn.html?user=meteorshowers&repo=Sora-Generates-Videos-with-Stunning-Geometrical-Consistency&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
	</td></tr></tbody></table><br>

  <table class="imgtable"><tbody><tr><td>
	<img src="figs/ma.gif"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://arxiv.org/abs/2311.16498">Magicanimate: Temporally consistent human image animation using diffusion model.</a></b><br>
		Zhongcong Xu, Jianfeng Zhang, Jun Hao Liew, Hanshu Yan, Jia-Wei Liu, <b>Chenxu Zhang</b>, Jiashi Feng, Mike Zheng Shou.<br>
		<i>Computer Vision and Pattern Recognition (CVPR), 2024.</i>
		<br>
			<a href="https://arxiv.org/abs/2311.16498">[paper]</a>&nbsp;&nbsp;
			<a href="https://showlab.github.io/magicanimate/">[project page]</a>&nbsp;&nbsp;
			<a href="https://github.com/magic-research/magic-animate">[code]</a>
	    		<iframe src="https://ghbtns.com/github-btn.html?user=magic-research&repo=magic-animate&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
	</td></tr></tbody></table><br>
	    
    <table class="imgtable"><tbody><tr><td>
	<img src="figs/wacv1.gif"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://personal.utdallas.edu/~xguo/WACV2024.pdf">DR2: Disentangled Recurrent Representation Learning for Data-efficient Speech Video Synthesis.</a></b><br>
		<b>Chenxu Zhang</b>, Chao Wang, Yifan Zhao, Shuo Cheng, Linjie Luo, Xiaohu Guo.<br>
		<i>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), 2024.</i>
		<br>
			<a href="https://personal.utdallas.edu/~xguo/WACV2024.pdf">[paper]</a>&nbsp;&nbsp;
			<a href="https://personal.utdallas.edu/~xguo/WACV2024_Supplement.pdf">[supplement]</a>&nbsp;&nbsp;
			<a href="https://www.youtube.com/watch?v=LDdDm86Ve_4">[video]</a>
	</td></tr></tbody></table><br>

    <table class="imgtable"><tbody><tr><td>
	<img src="figs/magicboost.gif"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://arxiv.org/abs/2404.06429">Magic-Boost: Boost 3D Generation with Mutli-View Conditioned Diffusion.</a></b><br>
	        Fan Yang, Jianfeng Zhang, Yichun Shi, Bowen Chen, <b>Chenxu Zhang</b>, Huichao Zhang, Xiaofeng Yang, Jiashi Feng, Guosheng Lin.<br>
		<i>Preprint'24.</i>
		<br>
			<a href="https://arxiv.org/abs/2404.06429">[paper]</a>&nbsp;&nbsp;
			<a href="https://magic-research.github.io/magic-boost/">[project page]</a>&nbsp;&nbsp;
			<a href="https://github.com/magic-research/magic-boost">[code]</a>
	    		<iframe src="https://ghbtns.com/github-btn.html?user=magic-research&repo=magic-boost&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
	</td></tr></tbody></table><br>

    <table class="imgtable"><tbody><tr><td>
	<img src="figs/iccv.gif"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://personal.utdallas.edu/~xguo/ICCV2021.pdf">FACIAL: Synthesizing Dynamic Talking Face with Implicit Attribute Learning.</a></b><br>
		<b>Chenxu Zhang</b>, Yifan Zhao, Yifei Huang, Ming Zeng, Saifeng Ni, Madhukar Budagavi, Xiaohu Guo.<br>
		<i>International Conference on Computer Vision (ICCV), 2021.</i>
		<br>
			<a href="https://personal.utdallas.edu/~xguo/ICCV2021.pdf">[paper]</a>&nbsp;&nbsp;
			<a href="https://www.youtube.com/watch?v=hl9ek3bUV1E">[video]</a>&nbsp;&nbsp;
			<a href="https://github.com/zhangchenxu528/FACIAL">[code]</a>
	    		<iframe src="https://ghbtns.com/github-btn.html?user=zhangchenxu528&repo=FACIAL&type=star&count=true" frameborder="0" scrolling="0" width="150" height="20" title="GitHub"></iframe>
	</td></tr></tbody></table><br>
	
	<table class="imgtable"><tbody><tr><td>
	<img src="figs/tvcg.gif"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://personal.utdallas.edu/~xguo/TVCG2021.pdf">3D Talking Face with Personalized Pose Dynamics.</a></b><br>
		<b>Chenxu Zhang</b>, Saifeng Ni, Zhipeng Fan, Hongbo Li, Ming Zeng, Madhukar Budagavi, Xiaohu Guo.<br>
		<i>IEEE Transactions on Visualization and Computer Graphics (TVCG), 2021.</i>
		<br>
			<a href="https://personal.utdallas.edu/~xguo/TVCG2021.pdf">[paper]</a>&nbsp;&nbsp;
			<a href="https://www.youtube.com/watch?v=KflYlxiia5Q">[video]</a>&nbsp;&nbsp;
	</td></tr></tbody></table><br>
	
	<table class="imgtable"><tbody><tr><td>	
	<img src="figs/MM20.jpg"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://personal.utdallas.edu/~xguo/MM2020.pdf">DeSmoothGAN: Recovering Details of Smoothed Images via Spatial Feature-wise Transformation and Full Attention.</a></b><br>
		Yifei Huang, Chenhui Li, Xiaohu Guo, Jing Liao, <b>Chenxu Zhang</b>, Changbo Wang.<br>
		<i>Proceedings of the 28th ACM International Conference on Multimedia (MM), 2020.</i>
		<br>
			<a href="https://personal.utdallas.edu/~xguo/MM2020.pdf">[paper]</a>&nbsp;&nbsp;
			<a href="https://personal.utdallas.edu/~xguo/MM2020_SUPP.pdf">[supplement]</a>&nbsp;&nbsp;
	</td></tr></tbody></table><br>
	
	
	<table class="imgtable"><tbody><tr><td>
	<img src="figs/fitee.jpg"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://link.springer.com/article/10.1631/FITEE.1800693">Modeling Yarn-level Geometry from a Single Micro-image.</a></b><br>
		Hongyu Wu, Xiaowu Chen, <b>Chenxu Zhang</b>, Bin Zhou, Qinping Zhao.<br>
		<i>Frontiers of Information Technology Electronic Engineering, 2019.</i>
		<br>
			<a href="https://link.springer.com/article/10.1631/FITEE.1800693">[paper]</a>&nbsp;&nbsp;
	</td></tr></tbody></table><br>
	
	<table class="imgtable"><tbody><tr><td>
	<img src="figs/jcst.jpg"  width="180px" >&nbsp;</td>
    <td align="left"><b><style="font-size:100%">
        <a  href="https://link.springer.com/article/10.1007/s11390-018-1831-6">Modeling Garment Seam from a Single Image.</a></b><br>
		<b>Chenxu Zhang</b>, Xiaowu Chen, Hongyu Wu, Bin Zhou.<br>
		<i>Journal of Computer Science and Technology (JCST), 2018.</i>
		<br>
			<a href="https://link.springer.com/article/10.1007/s11390-018-1831-6">[paper]</a>&nbsp;&nbsp;
	</td></tr></tbody></table>
	

</ul>

<h2>Activities</h2>
<ul>
<li> Reviewer for Journal: TPAMI, TIP, TMM, etc.
</li>
<li> Reviewer for Conference: CVPR, ICCV, ECCV, AAAI, MM, PG, WACV, etc.
</li>
</ul>

	    
</td>
</tr>
</tbody></table>


</body></html>
